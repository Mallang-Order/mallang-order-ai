import torch
from transformers import AutoModelForCTC, AutoProcessor
import sounddevice as sd
import numpy as np
import tkinter as tk
from tkinter import messagebox
from transformers import WhisperForConditionalGeneration, WhisperProcessor

model = WhisperForConditionalGeneration.from_pretrained(
    "C:\\Users\\user\\Desktop\\4-1\\ìº¡ìŠ¤í†¤ë””ìì¸\\í•œ-ì˜ ìŒì„±ë°œí™” ë°ì´í„°_ìŒì‹\\whisper_finetuned_ko\\checkpoint-4000"
).to('cuda')
processor = WhisperProcessor.from_pretrained("openai/whisper-small")
print("ğŸ”¥ í•™ìŠµëœ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")


# ë…¹ìŒ í•¨ìˆ˜ (ë¬´ìŒ ê°ì§€ í¬í•¨)
def record_audio(max_duration=7, samplerate=16000, silence_threshold=0.01, silence_duration=0.5):
    print("ğŸ¤ ë…¹ìŒ ì‹œì‘...")
    audio = []
    silence_counter = 0
    block_size = int(0.1 * samplerate)  # 0.1ì´ˆ ë‹¨ìœ„ë¡œ ì²´í¬

    stream = sd.InputStream(samplerate=samplerate, channels=1, dtype='float32', blocksize=block_size)
    stream.start()

    while True:
        block, _ = stream.read(block_size)
        block = block.squeeze()
        audio.append(block)

        volume = np.linalg.norm(block)  # ì†Œë¦¬ í¬ê¸° ê³„ì‚°
        if volume < silence_threshold:
            silence_counter += 0.1
        else:
            silence_counter = 0  # ì†Œë¦¬ê°€ ë‚˜ë©´ ë¦¬ì…‹

        # ë¬´ìŒì´ ì¼ì • ì‹œê°„ ì§€ì†ë˜ë©´ ì¢…ë£Œ
        if silence_counter > silence_duration:
            print("ğŸ›‘ ë¬´ìŒ ê°ì§€! ë…¹ìŒ ì¢…ë£Œ.")
            break

        # ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì´ˆê³¼
        if len(audio) * 0.1 > max_duration:
            print("â° ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì´ˆê³¼, ìë™ ì¢…ë£Œ.")
            break

    stream.stop()
    stream.close()
    audio = np.concatenate(audio)
    print("âœ… ë…¹ìŒ ì™„ë£Œ.")
    return audio


# ìŒì„± ì¸ì‹ í•¨ìˆ˜
def transcribe_audio(audio_data, samplerate=16000):
    inputs = processor(audio_data, sampling_rate=samplerate, return_tensors="pt")
    input_features = inputs.input_features.to('cuda')

    forced_decoder_ids = processor.get_decoder_prompt_ids(language="korean", task="transcribe")

    with torch.no_grad():
        generated_ids = model.generate(
            input_features,
            forced_decoder_ids=forced_decoder_ids
        )

    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return transcription


# ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰ í•¨ìˆ˜
def on_button_click():
    try:
        audio_data = record_audio(max_duration=10)
        text = transcribe_audio(audio_data)
        print("ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸:", text)
        messagebox.showinfo("ìŒì„± ì¸ì‹ ê²°ê³¼", text)
    except Exception as e:
        print("âŒ ì—ëŸ¬:", e)
        messagebox.showerror("ì—ëŸ¬", str(e))


# ê°„ë‹¨í•œ GUI
root = tk.Tk()
root.title("ìŒì„± ì¸ì‹ í‚¤ì˜¤ìŠ¤í¬ í…ŒìŠ¤íŠ¸")

button = tk.Button(root, text="ğŸ¤ ë…¹ìŒ ì‹œì‘", command=on_button_click, font=("Arial", 20), width=20, height=2)
button.pack(pady=30)

root.mainloop()