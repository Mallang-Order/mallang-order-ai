import pickle
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments
from datasets import Dataset
import time
from transformers import DataCollatorForSeq2Seq
from dataclasses import dataclass
from typing import Any, List, Dict, Union

# ëª¨ë¸ ì´ë¦„
model_name = "openai/whisper-small"

# ì €ì¥ëœ ì „ì²˜ë¦¬ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
with open("train_dataset_processed.pkl", "rb") as f:
    train_dataset = pickle.load(f)

with open("val_dataset_processed.pkl", "rb") as f:
    val_dataset = pickle.load(f)

# GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
device = "cuda:0" if torch.cuda.is_available() else "cpu"
#device="cpu"

# Processorì™€ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = WhisperForConditionalGeneration.from_pretrained(model_name, torch_dtype=torch.float32)
model.to(device)
processor = WhisperProcessor.from_pretrained(model_name, language='Korean')

@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    processor: Any

    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        # ì˜¤ë””ì˜¤ ì…ë ¥ ì²˜ë¦¬
        input_features = [{"input_features": feature["input_features"]} for feature in features]
        batch = self.processor.feature_extractor.pad(input_features, return_tensors="pt")
        #print("ğŸ“ input_features shape:", batch["input_features"].shape)

        # ë ˆì´ë¸” ì²˜ë¦¬
        label_features = [{"input_ids": feature["labels"]} for feature in features]
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")

        # íŒ¨ë”©ëœ ë ˆì´ë¸”ì—ì„œ -100ìœ¼ë¡œ ì±„ì›Œì„œ ì†ì‹¤ì—ì„œ ì œì™¸
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

        # BOS í† í° ì œê±° (ì´ë¯¸ ì¶”ê°€ëœ ìƒíƒœì¼ ê²½ìš°)
        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():
            labels = labels[:, 1:]

        batch["labels"] = labels

        return batch


# Data Collator ì´ë‹ˆì…œë¼ì´ì¦ˆ
data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)

# Data collator ì„¤ì •
#data_collator = DataCollatorForSeq2Seq(processor, model=model, padding=True)
#data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)


# í•™ìŠµ ì„¸íŒ…
training_args = Seq2SeqTrainingArguments(
    output_dir="C:\\Users\\user\\Desktop\\4-1\\ìº¡ìŠ¤í†¤ë””ìì¸\\í•œ-ì˜ ìŒì„±ë°œí™” ë°ì´í„°_ìŒì‹\\whisper_finetuned_ko",
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    gradient_accumulation_steps=8,

    learning_rate=1e-5,
    warmup_steps=500,
    max_steps=4000,
    gradient_checkpointing=False,
    predict_with_generate=True,
    fp16=False,

    evaluation_strategy="steps",
    #save_strategy="epoch",

    generation_max_length=128,
    save_steps=1000,
    eval_steps=1000,
    logging_steps=50,

    #report_to=["tensorboard"],
    load_best_model_at_end=True,

    #num_train_epochs=3,
    #logging_steps=20,
    #save_total_limit=2,
    report_to="none",
    #save_total_limit=1,
)

# íŠ¸ë ˆì´ë„ˆ
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    #tokenizer=processor,
    tokenizer=processor,#.feature_extractor,
    data_collator=data_collator,
    #compute_metrics=compute_metrics,
    #callbacks=[PrintRemainingTimeCallback()],
)

# í•™ìŠµ ì‹œì‘
trainer.train()