import pickle
import torch
from tqdm import tqdm
from transformers import WhisperForConditionalGeneration, WhisperProcessor

# ì „ì²˜ë¦¬ëœ validation ë°ì´í„° ë¡œë“œ
with open("val_dataset_processed.pkl", "rb") as f:
    val_dataset_processed = pickle.load(f)

device = "cuda" if torch.cuda.is_available() else "cpu"

model_name = "openai/whisper-small"
processor = WhisperProcessor.from_pretrained(model_name, language="Korean", task="transcribe")
decoder_ids = processor.get_decoder_prompt_ids(language="korean", task="transcribe")

# 1. Base ëª¨ë¸ ì¶”ë¡ 
print("ğŸš€ Base ëª¨ë¸ ì¶”ë¡  ì¤‘...")
base_model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device).eval()
base_refs = []
base_hyps = []

for sample in tqdm(val_dataset_processed):
    input_features = torch.tensor(sample["input_features"], dtype=torch.float32).unsqueeze(0).to(device)
    predicted_ids = base_model.generate(input_features, forced_decoder_ids=decoder_ids)
    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]

    base_refs.append(sample["text"])
    base_hyps.append(transcription)

# 2. Fine-tuned ëª¨ë¸ ì¶”ë¡ 
print("ğŸš€ Fine-tuned ëª¨ë¸ ì¶”ë¡  ì¤‘...")
finetuned_model_path = "C:\\Users\\user\\Desktop\\4-1\\ìº¡ìŠ¤í†¤ë””ìì¸\\í•œ-ì˜ ìŒì„±ë°œí™” ë°ì´í„°_ìŒì‹\\whisper_finetuned_ko\\checkpoint-4000"
finetuned_model = WhisperForConditionalGeneration.from_pretrained(finetuned_model_path).to(device).eval()
fine_hyps = []

for sample in tqdm(val_dataset_processed):
    input_features = torch.tensor(sample["input_features"], dtype=torch.float32).unsqueeze(0).to(device)
    predicted_ids = finetuned_model.generate(input_features, forced_decoder_ids=decoder_ids)
    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]

    fine_hyps.append(transcription)

# ê²°ê³¼ ì €ì¥
with open("cer_refs_and_hyps.pkl", "wb") as f:
    pickle.dump({
        "refs": base_refs,
        "base_hyps": base_hyps,
        "fine_hyps": fine_hyps
    }, f)

print("âœ… ì¶”ë¡  ì™„ë£Œ ë° ê²°ê³¼ ì €ì¥ë¨: cer_refs_and_hyps.pkl")